{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a73c557c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## <font color = darkblue> Tree Based Models\n",
    "    - Make sure to pip install xgboost\n",
    "    - This program uses a breast cancer related data that comes with sklearn\n",
    "    - For more information:\n",
    "        https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)\n",
    "\n",
    "<font color = red> The program also shows how to save (pickle) a model and call back later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa37b2b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Import dependencies\n",
    "# -------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# -------------------------\n",
    "# Load breast cancer data\n",
    "# -------------------------\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Note that the data comes as a util.bunch (dictionary)\n",
    "# --------------------------------------------------\n",
    "type(cancer)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Listing various attributes of the data structure\n",
    "# --------------------------------------------------\n",
    "print(list(cancer.keys()))\n",
    "\n",
    "# cancerdf = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2de5a6bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Creating the dataframe (df)\n",
    "# ------------------------------\n",
    "\n",
    "cancerdf = pd.DataFrame(cancer.data, columns = cancer.feature_names) \n",
    "cancerdf.head()\n",
    "\n",
    "print(cancer.DESCR)\n",
    "\n",
    "# ------------------------------\n",
    "# Response variable\n",
    "# 0 = Malignant, 1 = Benign\n",
    "# ------------------------------\n",
    "cancerdf[\"Response\"]= cancer.target\n",
    "cancerdf[\"Response\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ddf722",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## <font color = darkred> Details\n",
    "    - As can be seen above that the response classes are slightly imbalanced (~ in the ratio of 4:7) \n",
    "    - Code for various tree based models is provided below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd8400d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Split the dataset into training and testing sets\n",
    "# ------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data[:,15:20], cancer.target, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d412ce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## <font color = green> Decision tree\n",
    "    - Single tree \n",
    "    - The example belows shows modeling for a binary classification problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "005446e1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.77      0.73        43\n",
      "           1       0.85      0.79      0.82        71\n",
      "\n",
      "    accuracy                           0.78       114\n",
      "   macro avg       0.77      0.78      0.77       114\n",
      "weighted avg       0.79      0.78      0.78       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y_test</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_pred_dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y_test      0   1\n",
       "y_pred_dt        \n",
       "0          33  15\n",
       "1          10  56"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Train a decision tree classifier on the balanced dataset\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='gini',\n",
    "                             min_samples_split=5,\n",
    "                             min_samples_leaf=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Evaluate the classifier on the testing set\n",
    "# --------------------------------------------\n",
    "y_pred_dt = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "confusion_matrix(y_test, y_pred_dt)\n",
    "\n",
    "# Confusion Matrix\n",
    "pd.crosstab(y_pred_dt, y_test, rownames =['y_pred_dt'], colnames = ['y_test'] )\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Notes for reading the classification report\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# --------------\n",
    "# Precision: \n",
    "# --------------\n",
    "# Measures the proportion of true positives (TP) out of all predicted positives (TP + false positives (FP)). \n",
    "# A high precision means the model makes few false positive predictions.\n",
    "\n",
    "# --------------\n",
    "# Recall: \n",
    "# --------------\n",
    "# Measures the proportion of true positives (TP) out of all actual positives (TP + false negatives (FN)). \\\n",
    "# A high recall indicates that the model makes few false negative predictions.\n",
    "\n",
    "# --------------\n",
    "# F1-score: \n",
    "# --------------\n",
    "# It is the harmonic mean of precision and recall, calculated as (2 * precision * recall) / (precision + recall). \n",
    "# It is useful especially when the classes are imbalanced \n",
    "\n",
    "# --------------\n",
    "# Support: \n",
    "# --------------\n",
    "# It is the number of observations in each class.\n",
    "\n",
    "# --------------\n",
    "# Weighted Average: \n",
    "# --------------\n",
    "# It is calculated as the average of the precision, recall etc. weighted by the number of samples in each class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66372714",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## <font color = green> Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d37d7899",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8508771929824561\n",
      "Random Forest Precision: 0.8648648648648649\n",
      "Random Forest Recall: 0.9014084507042254\n",
      "Random Forest F1 Score: 0.8827586206896552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.77      0.80        43\n",
      "           1       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.85       114\n",
      "   macro avg       0.84      0.83      0.84       114\n",
      "weighted avg       0.85      0.85      0.85       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y_test</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_pred_rf</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y_test      0   1\n",
       "y_pred_rf        \n",
       "0          33   7\n",
       "1          10  64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ------------------\n",
    "# Define the RF model\n",
    "# ------------------\n",
    "rf = RandomForestClassifier(n_estimators=1000,\n",
    "                            criterion='entropy',\n",
    "                            min_samples_split=5,\n",
    "                            min_samples_leaf=5,\n",
    "                            random_state=100)\n",
    "\n",
    "# ------------------\n",
    "# Train the models\n",
    "# ------------------\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# ------------------------------------\n",
    "# Make predictions on the test set\n",
    "# ------------------------------------\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# Evaluate the model using accuracy, precision, recall, and F1 score\n",
    "# ------------------------------------------------------------------------\n",
    "print('Random Forest Accuracy:', accuracy_score(y_test, y_pred_rf))\n",
    "print('Random Forest Precision:', precision_score(y_test, y_pred_rf))\n",
    "print('Random Forest Recall:', recall_score(y_test, y_pred_rf))\n",
    "print('Random Forest F1 Score:', f1_score(y_test, y_pred_rf))\n",
    "\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Confusion Matrix\n",
    "pd.crosstab(y_pred_rf, y_test, rownames =['y_pred_rf'], colnames = ['y_test'] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1ee1a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## <font color = darkgreen> Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5d63a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.7807017543859649\n",
      "Gradient Boosting Precision: 0.8108108108108109\n",
      "Gradient Boosting Recall: 0.8450704225352113\n",
      "Gradient Boosting F1 Score: 0.8275862068965518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.70        43\n",
      "           1       0.81      0.85      0.83        71\n",
      "\n",
      "    accuracy                           0.78       114\n",
      "   macro avg       0.77      0.76      0.76       114\n",
      "weighted avg       0.78      0.78      0.78       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y_test</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_pred_gb</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y_test      0   1\n",
       "y_pred_gb        \n",
       "0          29  11\n",
       "1          14  60"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# ------------------\n",
    "# Define the GB model\n",
    "# ------------------\n",
    "gb = GradientBoostingClassifier(n_estimators=500,\n",
    "                            min_samples_split=5,\n",
    "                            learning_rate=0.5,\n",
    "                            min_samples_leaf=5,\n",
    "                            random_state=100)\n",
    "\n",
    "# ------------------\n",
    "# Train the model\n",
    "# ------------------\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# ------------------------------------\n",
    "# Make predictions on the test set\n",
    "# ------------------------------------\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# Evaluate the model using accuracy, precision, recall, and F1 score\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "print('Gradient Boosting Accuracy:', accuracy_score(y_test, y_pred_gb))\n",
    "print('Gradient Boosting Precision:', precision_score(y_test, y_pred_gb))\n",
    "print('Gradient Boosting Recall:', recall_score(y_test, y_pred_gb))\n",
    "print('Gradient Boosting F1 Score:', f1_score(y_test, y_pred_gb))\n",
    "\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "# Confusion Matrix\n",
    "pd.crosstab(y_pred_gb, y_test, rownames =['y_pred_gb'], colnames = ['y_test'] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dab1cbd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## <font color = Green> XGBoost\n",
    "    - Documentation and tutorial\n",
    "    https://xgboost.readthedocs.io/en/stable/tutorials/model.html\n",
    "    \n",
    "### <font color = red> Make sure to pip install xgboost library\n",
    "    !pip install xgboost\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10611325",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# help(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b632494",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB: 0.7894736842105263\n",
      "XGB: 0.8133333333333334\n",
      "XGB: 0.8591549295774648\n",
      "XGB: 0.8356164383561644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.71        43\n",
      "           1       0.81      0.86      0.84        71\n",
      "\n",
      "    accuracy                           0.79       114\n",
      "   macro avg       0.78      0.77      0.77       114\n",
      "weighted avg       0.79      0.79      0.79       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y_test</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_pred_xgb</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y_test       0   1\n",
       "y_pred_xgb        \n",
       "0           29  10\n",
       "1           14  61"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# ------------------\n",
    "# Define the XGB model\n",
    "# ------------------\n",
    "xgb = xgb.XGBClassifier(n_estimators=100,\n",
    "                        max_depth = 10,\n",
    "                        eta= 0.01,\n",
    "                        min_child_weight = 5,\n",
    "                        random_state=100)\n",
    "\n",
    "# ------------------\n",
    "# Train the model\n",
    "# ------------------\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# ------------------------------------\n",
    "# Make predictions on the test set\n",
    "# ------------------------------------\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# Evaluate the model using accuracy, precision, recall, and F1 score\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "print('XGB:', accuracy_score(y_test, y_pred_xgb))\n",
    "print('XGB:', precision_score(y_test, y_pred_xgb))\n",
    "print('XGB:', recall_score(y_test, y_pred_xgb))\n",
    "print('XGB:', f1_score(y_test, y_pred_xgb))\n",
    "\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "# Confusion Matrix\n",
    "pd.crosstab(y_pred_xgb, y_test, rownames =['y_pred_xgb'], colnames = ['y_test'] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f331c74b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## <font color= blue> How to \"pickle\" a model and call back later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f8b1876",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/prashantmittal/Roux\n",
      "[1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0\n",
      " 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "%cd '/Users/prashantmittal/Roux'\n",
    "\n",
    "\n",
    "# Serialize the random forest classifier to a file\n",
    "# Note that the file rf.pickle is created in the working directory\n",
    "\n",
    "with open('rf.pickle', 'wb') as handle:\n",
    "    pickle.dump(rf, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# # Deserialize the classifier from the file\n",
    "with open('rf.pickle', 'rb') as handle:\n",
    "    classifier_loaded = pickle.load(handle)\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "# # Use the loaded RF classifier to make predictions\n",
    "#----------------------------------------------------------------\n",
    "predicted_y = classifier_loaded.predict(X_test)\n",
    "\n",
    "print(predicted_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3cb780",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}